{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is the difference between AI, ML, DL, and Data Science?\n",
        "\n",
        "Artificial Intelligence (AI): Broad field that aims to make machines mimic human intelligence such as reasoning, problem solving, and decision-making.  \n",
        "Machine Learning (ML): Subset of AI that lets systems learn from data to make predictions or decisions without explicit programming.  \n",
        "Deep Learning (DL): Subset of ML that uses multi-layered neural networks to automatically extract complex patterns from large datasets.  \n",
        "Data Science: An interdisciplinary field combining statistics, mathematics, programming, and domain knowledge to extract insights and build predictive models.\n",
        "\n",
        "AI > ML > DL represents the hierarchy of scope, while Data Science spans across all by using data handling, visualization, and modeling.\n"
      ],
      "metadata": {
        "id": "3daHcD6qFTy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain overfitting and underfitting in ML. How can you detect and prevent them?\n",
        "\n",
        "Underfitting occurs when a model is too simple to capture the underlying data patterns — it performs poorly on both training and test data (high bias).\n",
        "\n",
        "Overfitting happens when a model learns the noise in the training data — it performs well on training data but poorly on unseen data (high variance).\n",
        "\n",
        "Detection:\n",
        "- Compare training and validation accuracy.\n",
        "- If training accuracy is high but validation accuracy is low → overfitting.\n",
        "- If both accuracies are low → underfitting.\n",
        "\n",
        "Prevention Methods:\n",
        "1. Cross-validation: Split data into folds to ensure consistent performance.\n",
        "2. Regularization: Add penalties (L1/L2) to prevent overly complex models.\n",
        "3. Early Stopping: Stop training when validation error increases.\n",
        "4. Simplify model (reduce parameters) or collect more data.\n",
        "5. Use Dropout or Data Augmentation (for neural networks).\n",
        "\n",
        "Bias–Variance Trade-off:\n",
        "Aim for a balance between low bias (enough complexity) and low variance (good generalization).\n"
      ],
      "metadata": {
        "id": "kp1i2Pf8FeLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: How would you handle missing values in a dataset? Explain at least three methods with examples.\n",
        "\n",
        "Missing values occur when no data is stored for a variable in an observation. Handling them properly is essential to maintain model accuracy and data integrity.\n",
        "\n",
        "Common Methods:\n",
        "\n",
        "1. Deletion (Listwise or Pairwise)\n",
        "   - Remove rows or columns with missing values.\n",
        "   - Best when missing data is very small and random.\n",
        "   - Example: df.dropna()\n",
        "\n",
        "2. Imputation (Mean / Median / Mode)\n",
        "   - Replace missing values with a representative statistic.\n",
        "   - Mean or median for numerical data; mode for categorical.\n",
        "   - Example: df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
        "\n",
        "3. Predictive Imputation\n",
        "   - Use other features to predict the missing value.\n",
        "   - Techniques include KNN Imputer or regression models.\n",
        "   - Example: from sklearn.impute import KNNImputer\n",
        "\n",
        "Other methods:\n",
        "- Use a constant (e.g., “Unknown”) for categorical variables.\n",
        "- Create an indicator column showing where data was missing.\n"
      ],
      "metadata": {
        "id": "GLn0kX7QFh0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values in Python\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Sample Data\n",
        "data = {\n",
        "    'Age': [25, 30, None, 22, None],\n",
        "    'Salary': [50000, None, 40000, 35000, 45000],\n",
        "    'City': ['Delhi', None, 'Mumbai', 'Delhi', 'Kolkata']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original Data:\\n\", df)\n",
        "\n",
        "# 1. Deletion\n",
        "df_drop = df.dropna()\n",
        "print(\"\\nAfter Deletion:\\n\", df_drop)\n",
        "\n",
        "# 2. Imputation with Median / Mode\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
        "df['City'].fillna(df['City'].mode()[0], inplace=True)\n",
        "print(\"\\nAfter Simple Imputation:\\n\", df)\n",
        "\n",
        "# 3. KNN Imputation (Predictive)\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "numeric_cols = ['Age', 'Salary']\n",
        "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "print(\"\\nAfter KNN Imputation:\\n\", df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRkAu9GmFzQM",
        "outputId": "70e00706-bd96-47de-87ba-d422ebdaf9e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "     Age   Salary     City\n",
            "0  25.0  50000.0    Delhi\n",
            "1  30.0      NaN     None\n",
            "2   NaN  40000.0   Mumbai\n",
            "3  22.0  35000.0    Delhi\n",
            "4   NaN  45000.0  Kolkata\n",
            "\n",
            "After Deletion:\n",
            "     Age   Salary   City\n",
            "0  25.0  50000.0  Delhi\n",
            "3  22.0  35000.0  Delhi\n",
            "\n",
            "After Simple Imputation:\n",
            "     Age   Salary     City\n",
            "0  25.0  50000.0    Delhi\n",
            "1  30.0  42500.0    Delhi\n",
            "2  25.0  40000.0   Mumbai\n",
            "3  22.0  35000.0    Delhi\n",
            "4  25.0  45000.0  Kolkata\n",
            "\n",
            "After KNN Imputation:\n",
            "     Age   Salary     City\n",
            "0  25.0  50000.0    Delhi\n",
            "1  30.0  42500.0    Delhi\n",
            "2  25.0  40000.0   Mumbai\n",
            "3  22.0  35000.0    Delhi\n",
            "4  25.0  45000.0  Kolkata\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1578780328.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "/tmp/ipython-input-1578780328.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
            "/tmp/ipython-input-1578780328.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['City'].fillna(df['City'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is an imbalanced dataset? Describe two techniques to handle it.\n",
        "\n",
        "An imbalanced dataset is one where the number of samples in different classes is not equal — for example, 95% of class 0 and only 5% of class 1.  \n",
        "This causes models to become biased toward the majority class, giving poor performance on the minority class.\n",
        "\n",
        "Two techniques to handle imbalance:\n",
        "\n",
        "1. Resampling Techniques\n",
        "   - Oversampling: Increase the minority class samples (e.g., SMOTE).\n",
        "   - Undersampling: Reduce samples from the majority class.\n",
        "   Example: Use SMOTE from imbalanced-learn library.\n",
        "\n",
        "2. Class Weight Adjustment\n",
        "   - Give higher penalty to misclassification of minority class.\n",
        "   - Many models (like Logistic Regression, Random Forest) have `class_weight='balanced'` parameter.\n",
        "\n",
        "Other helpful steps:\n",
        "- Use proper metrics like F1-score, Precision, Recall, and ROC-AUC instead of Accuracy.\n",
        "- Combine sampling with cross-validation to maintain balance.\n"
      ],
      "metadata": {
        "id": "OOqBiqF9F-z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling imbalanced dataset using SMOTE and Class Weights\n",
        "\n",
        "!pip install imbalanced-learn --quiet\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Create an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=5, weights=[0.9, 0.1], random_state=42)\n",
        "print(\"Original Class Distribution:\", {0: sum(y==0), 1: sum(y==1)})\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Without balancing\n",
        "model_unbalanced = LogisticRegression()\n",
        "model_unbalanced.fit(X_train, y_train)\n",
        "y_pred_unbalanced = model_unbalanced.predict(X_test)\n",
        "print(\"\\nWithout Balancing:\\n\", classification_report(y_test, y_pred_unbalanced))\n",
        "\n",
        "# 2. Using SMOTE (Oversampling minority class)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
        "print(\"\\nAfter SMOTE Resampling:\", {0: sum(y_res==0), 1: sum(y_res==1)})\n",
        "\n",
        "model_smote = LogisticRegression()\n",
        "model_smote.fit(X_res, y_res)\n",
        "y_pred_smote = model_smote.predict(X_test)\n",
        "print(\"\\nWith SMOTE:\\n\", classification_report(y_test, y_pred_smote))\n",
        "\n",
        "# 3. Using Class Weights\n",
        "model_weighted = LogisticRegression(class_weight='balanced')\n",
        "model_weighted.fit(X_train, y_train)\n",
        "y_pred_weighted = model_weighted.predict(X_test)\n",
        "print(\"\\nWith Class Weights:\\n\", classification_report(y_test, y_pred_weighted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tItY06ESGQUT",
        "outputId": "532ea8dd-08c8-4bdd-82be-34b0d082407f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Class Distribution: {0: np.int64(895), 1: np.int64(105)}\n",
            "\n",
            "Without Balancing:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       272\n",
            "           1       1.00      0.36      0.53        28\n",
            "\n",
            "    accuracy                           0.94       300\n",
            "   macro avg       0.97      0.68      0.75       300\n",
            "weighted avg       0.94      0.94      0.93       300\n",
            "\n",
            "\n",
            "After SMOTE Resampling: {0: np.int64(623), 1: np.int64(623)}\n",
            "\n",
            "With SMOTE:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94       272\n",
            "           1       0.47      0.82      0.60        28\n",
            "\n",
            "    accuracy                           0.90       300\n",
            "   macro avg       0.72      0.86      0.77       300\n",
            "weighted avg       0.93      0.90      0.91       300\n",
            "\n",
            "\n",
            "With Class Weights:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94       272\n",
            "           1       0.46      0.86      0.60        28\n",
            "\n",
            "    accuracy                           0.89       300\n",
            "   macro avg       0.72      0.88      0.77       300\n",
            "weighted avg       0.94      0.89      0.91       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Compare Label Encoding and One-Hot Encoding. When would you prefer one over the other?\n",
        "\n",
        "Label Encoding:\n",
        "- Converts categories to integers.\n",
        "- Best for ordinal variables (ordered).\n",
        "\n",
        "One-Hot Encoding:\n",
        "- Creates binary columns for each category.\n",
        "- Best for nominal variables (unordered).\n",
        "\n",
        "Preference:\n",
        "- Ordinal → Label Encoding\n",
        "- Nominal → One-Hot Encoding\n"
      ],
      "metadata": {
        "id": "0WxhZfYfIPwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Education': ['High School', 'Bachelor', 'Master', 'PhD'],\n",
        "    'Color': ['Red', 'Green', 'Blue', 'Green']\n",
        "})\n",
        "\n",
        "# Label Encoding for ordinal\n",
        "le = LabelEncoder()\n",
        "data['Education_Label'] = le.fit_transform(data['Education'])\n",
        "\n",
        "# One-Hot Encoding for nominal\n",
        "data = pd.concat([data, pd.get_dummies(data['Color'], prefix='Color')], axis=1)\n",
        "\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX3UKnhXIRKv",
        "outputId": "cc616288-0df6-40c8-91b0-41bd82afd91b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Education  Color  Education_Label  Color_Blue  Color_Green  Color_Red\n",
            "0  High School    Red                1       False        False       True\n",
            "1     Bachelor  Green                0       False         True      False\n",
            "2       Master   Blue                2        True        False      False\n",
            "3          PhD  Green                3       False         True      False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Analyze the relationship between app categories and ratings. Which categories have the highest/lowest average ratings, and what could be the possible reasons?\n",
        "\n",
        "- Group apps by category and calculate average ratings.\n",
        "- Categories with highest average ratings may have better app quality or user engagement.\n",
        "- Categories with lowest average ratings may have low-quality apps or inconsistent updates.\n"
      ],
      "metadata": {
        "id": "SJa83JKHIir8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset from GitHub URL\n",
        "url = \"https://raw.githubusercontent.com/MasteriNeuron/datasets/main/googleplaystore.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Clean data: remove rows with missing 'Rating'\n",
        "data = data[pd.notnull(data['Rating'])]\n",
        "\n",
        "# Convert 'Rating' to numeric\n",
        "data['Rating'] = pd.to_numeric(data['Rating'], errors='coerce')\n",
        "data = data[pd.notnull(data['Rating'])]\n",
        "\n",
        "# Group by 'Category' and calculate average rating\n",
        "category_ratings = data.groupby('Category')['Rating'].mean().sort_values(ascending=False)\n",
        "\n",
        "print(\"Average Ratings by Category:\\n\", category_ratings)\n",
        "\n",
        "# Highest and lowest rated categories\n",
        "print(\"\\nHighest rated category:\", category_ratings.idxmax(), \"->\", category_ratings.max())\n",
        "print(\"Lowest rated category:\", category_ratings.idxmin(), \"->\", category_ratings.min())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgRynGlUI0gK",
        "outputId": "3b389937-c100-4726-9535-bdc33f72e6f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Ratings by Category:\n",
            " Category\n",
            "1.9                    19.000000\n",
            "EVENTS                  4.435556\n",
            "EDUCATION               4.389032\n",
            "ART_AND_DESIGN          4.358065\n",
            "BOOKS_AND_REFERENCE     4.346067\n",
            "PERSONALIZATION         4.335987\n",
            "PARENTING               4.300000\n",
            "GAME                    4.286326\n",
            "BEAUTY                  4.278571\n",
            "HEALTH_AND_FITNESS      4.277104\n",
            "SHOPPING                4.259664\n",
            "SOCIAL                  4.255598\n",
            "WEATHER                 4.244000\n",
            "SPORTS                  4.223511\n",
            "PRODUCTIVITY            4.211396\n",
            "HOUSE_AND_HOME          4.197368\n",
            "FAMILY                  4.192272\n",
            "PHOTOGRAPHY             4.192114\n",
            "AUTO_AND_VEHICLES       4.190411\n",
            "MEDICAL                 4.189143\n",
            "LIBRARIES_AND_DEMO      4.178462\n",
            "FOOD_AND_DRINK          4.166972\n",
            "COMMUNICATION           4.158537\n",
            "COMICS                  4.155172\n",
            "NEWS_AND_MAGAZINES      4.132189\n",
            "FINANCE                 4.131889\n",
            "ENTERTAINMENT           4.126174\n",
            "BUSINESS                4.121452\n",
            "TRAVEL_AND_LOCAL        4.109292\n",
            "LIFESTYLE               4.094904\n",
            "VIDEO_PLAYERS           4.063750\n",
            "MAPS_AND_NAVIGATION     4.051613\n",
            "TOOLS                   4.047411\n",
            "DATING                  3.970769\n",
            "Name: Rating, dtype: float64\n",
            "\n",
            "Highest rated category: 1.9 -> 19.0\n",
            "Lowest rated category: DATING -> 3.9707692307692306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Titanic Dataset Analysis\n",
        "\n",
        "a) Compare the survival rates based on passenger class (Pclass).\n",
        "- Lower class passengers (3rd class) had lower survival rates due to limited access to lifeboats.\n",
        "- Higher class passengers (1st class) had the highest survival rates because of priority during evacuation.\n",
        "\n",
        "b) Analyze how age (Age) affected survival.\n",
        "- Group passengers into children (Age < 18) and adults (Age ≥ 18).\n",
        "- Children generally had a higher survival rate due to 'women and children first' policy during evacuation.\n"
      ],
      "metadata": {
        "id": "T1ZNsfHEI5L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset from GitHub URL\n",
        "url = \"https://raw.githubusercontent.com/MasteriNeuron/datasets/main/titanic.csv\"\n",
        "titanic = pd.read_csv(url)\n",
        "\n",
        "# a) Survival rate by Pclass\n",
        "pclass_survival = titanic.groupby('Pclass')['Survived'].mean()\n",
        "print(\"Survival Rate by Passenger Class:\\n\", pclass_survival)\n",
        "print(\"Highest survival class:\", pclass_survival.idxmax(), \"->\", pclass_survival.max())\n",
        "\n",
        "# b) Survival rate by age group\n",
        "titanic['AgeGroup'] = titanic['Age'].apply(lambda x: 'Child' if x < 18 else 'Adult')\n",
        "age_survival = titanic.groupby('AgeGroup')['Survived'].mean()\n",
        "print(\"\\nSurvival Rate by Age Group:\\n\", age_survival)\n",
        "print(\"Children had better chance of survival:\", age_survival['Child'] > age_survival['Adult'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmnEmI2SJCld",
        "outputId": "337240f1-b078-45bc-db15-4fa16b727167"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Survival Rate by Passenger Class:\n",
            " Pclass\n",
            "1    0.629630\n",
            "2    0.472826\n",
            "3    0.242363\n",
            "Name: Survived, dtype: float64\n",
            "Highest survival class: 1 -> 0.6296296296296297\n",
            "\n",
            "Survival Rate by Age Group:\n",
            " AgeGroup\n",
            "Adult    0.361183\n",
            "Child    0.539823\n",
            "Name: Survived, dtype: float64\n",
            "Children had better chance of survival: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Flight Price Prediction Dataset\n",
        "\n",
        "a) Flight prices vs. days left until departure:\n",
        "- Prices usually increase exponentially as the departure date approaches.\n",
        "- Best booking window is typically 2–3 weeks in advance to get cheaper fares.\n",
        "\n",
        "b) Compare prices across airlines for the same route (Delhi-Mumbai):\n",
        "- Some airlines are consistently cheaper due to budget operations.\n",
        "- Premium airlines charge more due to better services and amenities.\n"
      ],
      "metadata": {
        "id": "LQ9VGx02JGxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset from GitHub URL\n",
        "url = \"https://raw.githubusercontent.com/MasteriNeuron/datasets/main/FlightPrices.csv\"\n",
        "flights = pd.read_csv(url)\n",
        "\n",
        "# a) Flight prices vs days left until departure\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(flights['DaysLeft'], flights['Price'], alpha=0.5)\n",
        "plt.xlabel('Days Left Until Departure')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Flight Price vs Days Left')\n",
        "plt.show()\n",
        "\n",
        "# b) Compare prices across airlines for Delhi-Mumbai\n",
        "route = flights[flights['Route'] == 'Delhi-Mumbai']\n",
        "airline_prices = route.groupby('Airline')['Price'].mean().sort_values()\n",
        "print(\"Average Prices by Airline for Delhi-Mumbai:\\n\", airline_prices)\n",
        "print(\"\\nCheapest Airline:\", airline_prices.idxmin(), \"->\", airline_prices.min())\n",
        "print(\"Premium Airline:\", airline_prices.idxmax(), \"->\", airline_prices.max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "HVOTuCjyJP-A",
        "outputId": "f22adae1-6da8-440e-dcbd-bd12a0ac6728"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-569823463.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load dataset from GitHub URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/MasteriNeuron/datasets/main/FlightPrices.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mflights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# a) Flight prices vs days left until departure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: HR Analytics Dataset\n",
        "\n",
        "a) Factors correlating with employee attrition:\n",
        "- Satisfaction level, overtime, and salary are strong indicators.\n",
        "- Low satisfaction, high overtime, and low salary increase attrition risk.\n",
        "\n",
        "b) Are employees with more projects more likely to leave?\n",
        "- Employees handling too many projects may have higher attrition due to stress and workload.\n"
      ],
      "metadata": {
        "id": "zXqWR6aAJsVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset from GitHub URL\n",
        "url = \"https://raw.githubusercontent.com/MasteriNeuron/datasets/main/hr_analytics.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# a) Correlation with attrition\n",
        "corr = data.corr(numeric_only=True)['left'].sort_values(ascending=False)\n",
        "print(\"Correlation with Attrition:\\n\", corr)\n",
        "\n",
        "# Visualize key drivers\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=corr.index, y=corr.values)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Correlation of Features with Attrition')\n",
        "plt.show()\n",
        "\n",
        "# b) Attrition vs number of projects\n",
        "projects_attrition = data.groupby('number_project')['left'].mean()\n",
        "print(\"\\nAttrition Rate by Number of Projects:\\n\", projects_attrition)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "projects_attrition.plot(kind='bar')\n",
        "plt.xlabel('Number of Projects')\n",
        "plt.ylabel('Attrition Rate')\n",
        "plt.title('Attrition Rate by Number of Projects')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "yJGKc6bqJteO",
        "outputId": "ed8df946-ef21-46db-990d-1cf5500f18dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'hr_analytics.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-660377985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load dataset (assuming CSV file 'hr_analytics.csv' is in local or Colab environment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hr_analytics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# a) Correlation with attrition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hr_analytics.csv'"
          ]
        }
      ]
    }
  ]
}